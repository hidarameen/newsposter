import logging
from typing import Optional, Tuple, Dict, List
from aiogram.types import Message, InlineKeyboardMarkup
from task_settings_manager import TaskSettingsManager
from subscription_manager import SubscriptionManager
from entity_handler import EntityHandler
from text_filters import TextFilters
from link_filters import LinkFilters
from button_filters import ButtonFilters
from media_filters import MediaFilters
from language_filters import LanguageFilters
from button_parser import ButtonParser
from day_filter import DayFilter
from hour_filter import HourFilter
from character_limit_filter import CharacterLimitFilter
from timezone_manager import TimezoneManager

logger = logging.getLogger(__name__)

class MessageProcessor:
    def __init__(self, user_id: int, task_id: int):
        self.user_id = user_id
        self.task_id = task_id
        self.settings_manager = TaskSettingsManager(user_id, task_id)
        self.subscription_manager = SubscriptionManager(user_id)

    def should_process_message(self, message: Message) -> Tuple[bool, str]:
        settings = self.settings_manager.load_settings()
        is_premium = self.subscription_manager.is_premium()

        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        tz_manager = TimezoneManager(self.user_id)
        timezone = tz_manager.get_timezone()

        # ÙÙ„ØªØ± Ø§Ù„Ø£ÙŠØ§Ù…
        day_filter = settings.get('day_filter', {})
        if is_premium and day_filter.get('enabled', False):
            allowed, reason = DayFilter.check_day_allowed(day_filter, timezone)
            if not allowed:
                return False, reason

        # ÙÙ„ØªØ± Ø§Ù„Ø³Ø§Ø¹Ø§Øª
        hour_filter = settings.get('hour_filter', {})
        if is_premium and hour_filter.get('enabled', False):
            allowed, reason = HourFilter.check_hour_allowed(hour_filter, timezone)
            if not allowed:
                return False, reason

        media_filter = settings['media_filters']
        if media_filter['enabled']:
            if not MediaFilters.is_media_allowed(message, media_filter['allowed_types']):
                return False, "Ù†ÙˆØ¹ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­"

        forwarded_filter = settings['forwarded_filter']
        if is_premium and forwarded_filter['enabled']:
            is_forwarded = message.forward_date is not None
            if not TextFilters.check_forwarded_filter(is_forwarded, forwarded_filter['mode']):
                return False, "Ø±Ø³Ø§Ù„Ø© Ù…ÙˆØ¬Ù‡Ø© Ù…Ø­Ø¸ÙˆØ±Ø©"

        button_filter = settings['button_filter']
        if is_premium and button_filter['enabled']:
            allowed, _ = ButtonFilters.apply_button_filter(message.reply_markup, button_filter['mode'])
            if not allowed:
                return False, "Ø§Ù„Ø±Ø³Ø§Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø²Ø±Ø§Ø± Ù…Ø­Ø¸ÙˆØ±Ø©"

        return True, ""

    def process_message_text(self, message: Message) -> Tuple[bool, Optional[str], List[Dict], str]:
        text = message.text or message.caption or ""
        original_entities = message.entities or message.caption_entities

        logger.info(f"ğŸ” process_message_text - Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: '{text}'")
        logger.info(f"ğŸ” process_message_text - entities Ø£ØµÙ„ÙŠØ©: {len(original_entities) if original_entities else 0}")
        if original_entities:
            for e in original_entities:
                logger.info(f"   Original Entity: {e.type} at {e.offset}:{e.offset+e.length}")

        entities = EntityHandler.entities_to_dict(original_entities, text)
        logger.info(f"ğŸ” Ø¨Ø¹Ø¯ entities_to_dict: {len(entities)} entities")

        if not text:
            return True, text, entities, ""

        settings = self.settings_manager.load_settings()
        is_premium = self.subscription_manager.is_premium()

        # ÙÙ„ØªØ± Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø£Ø­Ø±Ù
        char_limit = settings.get('character_limit', {})
        if is_premium and char_limit.get('enabled', False):
            allowed, reason = CharacterLimitFilter.check_character_limit(text, char_limit)
            if not allowed:
                return False, None, [], reason

        whitelist = settings['whitelist_words']
        if is_premium and whitelist['enabled']:
            allowed, reason = TextFilters.apply_whitelist(text, whitelist['words'])
            if not allowed:
                return False, None, [], reason

        blacklist = settings['blacklist_words']
        if is_premium and blacklist['enabled']:
            allowed, reason = TextFilters.apply_blacklist(text, blacklist['words'])
            if not allowed:
                return False, None, [], reason

        language_filter = settings['language_filter']
        if is_premium and language_filter['enabled']:
            allowed, reason = LanguageFilters.apply_language_filter(
                text,
                language_filter['mode'],
                language_filter['languages'],
                language_filter['sensitivity']
            )
            if not allowed:
                return False, None, [], reason

        link_mgmt = settings['link_management']
        if is_premium and link_mgmt['enabled']:
            allowed, text, entities = LinkFilters.apply_link_filter(text, link_mgmt['mode'], entities)
            if not allowed:
                return False, None, [], text

        replacements = settings['replacements']
        if is_premium and replacements['enabled']:
            text, entities = TextFilters.apply_replacements(text, replacements['pairs'], entities)

        # ØªØ®Ø·ÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙÙŠ process_message_text Ù„Ø£Ù†Ù‡Ø§ ØºÙŠØ± async
        # Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø³ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ ÙÙŠ integrated_media_handler.py Ø§Ù„Ø°ÙŠ ÙŠØ³ØªØ®Ø¯Ù… async
        # translation = settings.get('translation', {})
        # if is_premium and translation.get('enabled', False) and text:
        #     from translation_handler import TranslationHandler
        #     translator = TranslationHandler()
        #     try:
        #         translated, translated_text = await translator.process_translation(text, translation)
        #         if translated and translated_text:
        #             text = translated_text
        #             logger.info(f"âœ… ØªÙ…Øª ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­")
        #     except Exception as e:
        #         logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©: {e}")

        # ØªØ¹Ø·ÙŠÙ„ Ø¥Ø¶Ø§ÙØ© emoji Ù…Ø¤Ù‚ØªØ§Ù‹ Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ entities
        # Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªÙØ¹ÙŠÙ„Ù‡ Ø¨Ø¹Ø¯ Ø¥ØµÙ„Ø§Ø­ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ offsets
        # text, entities = self.add_emoji_prefix(text, entities)

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‡ÙŠØ¯Ø± Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ entities
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù‡Ù…Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… (ÙˆÙ„ÙŠØ³Øª Ø¥Ø¯Ø§Ø±ÙŠØ©)
        header = settings['header']
        if is_premium and header['enabled'] and header['text'] and self.user_id and self.task_id:
            header_saved_entities = header.get('entities', [])
            logger.info(f"ğŸ“‹ Ù‡ÙŠØ¯Ø± - Ø§Ù„Ù†Øµ: '{header['text']}'")
            logger.info(f"ğŸ“‹ Ù‡ÙŠØ¯Ø± - entities Ù…Ø­ÙÙˆØ¸Ø©: {len(header_saved_entities)}")
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ø¨ØµÙŠØºØ© UTF-16
            # Ø§Ù„Ù‡ÙŠØ¯Ø± + Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯
            header_with_newline = header['text'] + '\n'
            
            # Ø­Ø³Ø§Ø¨ Ø·ÙˆÙ„ Ø§Ù„Ù‡ÙŠØ¯Ø± Ø¨ØµÙŠØºØ© UTF-16
            shift_amount = 0
            for char in header_with_newline:
                # Emoji ÙˆØ§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ© (> U+FFFF) ØªØ£Ø®Ø° 2 units ÙÙŠ UTF-16
                if ord(char) > 0xFFFF:
                    shift_amount += 2
                else:
                    shift_amount += 1
            
            logger.info(f"ğŸ“‹ Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ù‡ÙŠØ¯Ø± (UTF-16): {shift_amount} (Ø·ÙˆÙ„ Python: {len(header_with_newline)})")
            
            # shift entities Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            shifted_message_entities = EntityHandler.shift_entities(entities, shift_amount)
            logger.info(f"ğŸ“‹ entities Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø²Ø§Ø­Ø©: {len(shifted_message_entities)}")
            
            # Ø¯Ù…Ø¬ entities Ø§Ù„Ù‡ÙŠØ¯Ø± Ù…Ø¹ entities Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø²Ø§Ø­Ø©
            entities = EntityHandler.merge_entities(header_saved_entities, shifted_message_entities)
            logger.info(f"ğŸ“‹ Ø¨Ø¹Ø¯ Ø¯Ù…Ø¬ Ø§Ù„Ù‡ÙŠØ¯Ø±: {len(entities)} entities")
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Øµ
            text = header['text'] + '\n' + text

        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙˆØªØ± Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ entities
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù‡Ù…Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… (ÙˆÙ„ÙŠØ³Øª Ø¥Ø¯Ø§Ø±ÙŠØ©)
        footer = settings['footer']
        if is_premium and footer['enabled'] and footer['text'] and self.user_id and self.task_id:
            footer_saved_entities = footer.get('entities', [])
            logger.info(f"ğŸ“‹ ÙÙˆØªØ± - Ø§Ù„Ù†Øµ: '{footer['text']}'")
            logger.info(f"ğŸ“‹ ÙÙˆØªØ± - entities Ù…Ø­ÙÙˆØ¸Ø©: {len(footer_saved_entities)}")
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ø¨ØµÙŠØºØ© UTF-16
            # Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ø§Ù„ÙŠ + Ø³Ø·Ø± Ø¬Ø¯ÙŠØ¯
            current_text_with_newline = text + '\n'
            
            # Ø­Ø³Ø§Ø¨ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¨ØµÙŠØºØ© UTF-16
            shift_amount = 0
            for char in current_text_with_newline:
                if ord(char) > 0xFFFF:
                    shift_amount += 2
                else:
                    shift_amount += 1
            
            logger.info(f"ğŸ“‹ Ø¥Ø²Ø§Ø­Ø© Ø§Ù„ÙÙˆØªØ± (UTF-16): {shift_amount} (Ø·ÙˆÙ„ Python: {len(current_text_with_newline)})")
            
            # shift entities Ø§Ù„ÙÙˆØªØ±
            shifted_footer_entities = EntityHandler.shift_entities(footer_saved_entities, shift_amount)
            
            # Ø¯Ù…Ø¬ entities Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù…Ø¹ entities Ø§Ù„ÙÙˆØªØ± Ø§Ù„Ù…Ø²Ø§Ø­Ø©
            entities = EntityHandler.merge_entities(entities, shifted_footer_entities)
            logger.info(f"ğŸ“‹ Ø¨Ø¹Ø¯ Ø¯Ù…Ø¬ Ø§Ù„ÙÙˆØªØ±: {len(entities)} entities")
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Øµ
            text = text + '\n' + footer['text']

        # ØªØ·Ø¨ÙŠÙ‚ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙˆØ­Ø¯ (Ø¢Ø®Ø± Ø®Ø·ÙˆØ© Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„)
        text_format = settings.get('text_format', {'enabled': False, 'format_type': 'normal', 'text_link_url': ''})
        if is_premium and text_format.get('enabled', False) and text_format.get('format_type'):
            from text_formatter import TextFormatter
            
            format_type = text_format['format_type']
            text_link_url = text_format.get('text_link_url', '')
            logger.info(f"ğŸ¨ [TextFormat] ØªØ·Ø¨ÙŠÙ‚ ØªÙ†Ø³ÙŠÙ‚ '{format_type}' Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
            logger.info(f"   ğŸ“Š Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚: {len(entities) if entities else 0} entities")
            
            text, entities = TextFormatter.apply_format(text, entities, format_type, text_link_url)
            
            logger.info(f"   ğŸ“Š Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚: {len(entities) if entities else 0} entities")

        logger.info(f"ğŸ” process_message_text - Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: '{text}'")
        logger.info(f"ğŸ” process_message_text - entities Ù†Ù‡Ø§Ø¦ÙŠØ© (dict): {len(entities) if entities else 0}")
        if entities:
            for e in entities[:5]:  # Ø£ÙˆÙ„ 5 ÙÙ‚Ø·
                logger.info(f"   Final Entity (dict): {e}")

        return True, text, entities, ""

    def get_reply_markup(self, message: Message, post_url: Optional[str] = None, message_text: Optional[str] = None) -> Optional[InlineKeyboardMarkup]:
        settings = self.settings_manager.load_settings()
        is_premium = self.subscription_manager.is_premium()

        button_filter = settings['button_filter']
        if is_premium and button_filter['enabled'] and button_filter['mode'] == 'remove':
            reply_markup = None
        else:
            reply_markup = message.reply_markup

        inline_buttons = settings['inline_buttons']
        if is_premium and inline_buttons['enabled'] and inline_buttons['buttons']:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Øµ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø£Ùˆ Ø§Ù„ÙƒØ§Ø¨Ø´Ù†
            text_for_sharing = message_text or message.text or message.caption or ''
            custom_markup = ButtonParser.buttons_to_markup(inline_buttons['buttons'], post_url or '', text_for_sharing)

            if reply_markup and hasattr(reply_markup, 'inline_keyboard'):
                combined_keyboard = custom_markup.inline_keyboard + reply_markup.inline_keyboard
                return InlineKeyboardMarkup(inline_keyboard=combined_keyboard)
            else:
                return custom_markup

        return reply_markup

    def get_settings_summary(self) -> str:
        settings = self.settings_manager.load_settings()
        is_premium = self.subscription_manager.is_premium()

        summary = "âš™ï¸ <b>Ù…Ù„Ø®Øµ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©:</b>\n\n"

        active_filters = []

        if settings['media_filters']['enabled']:
            active_filters.append(f"ğŸ“¹ ÙÙ„Ø§ØªØ± Ø§Ù„ÙˆØ³Ø§Ø¦Ø·")

        if is_premium and settings['header']['enabled']:
            active_filters.append(f"ğŸ“ Ø±Ø£Ø³ Ø§Ù„Ø±Ø³Ø§Ù„Ø©")

        if is_premium and settings['footer']['enabled']:
            active_filters.append(f"ğŸ“ Ø°ÙŠÙ„ Ø§Ù„Ø±Ø³Ø§Ù„Ø©")

        if is_premium and settings['inline_buttons']['enabled']:
            active_filters.append(f"ğŸ”˜ Ø£Ø²Ø±Ø§Ø± Ø¥Ù†Ù„Ø§ÙŠÙ†")

        if is_premium and settings['whitelist_words']['enabled']:
            active_filters.append(f"âœ… Ù‚Ø§Ø¦Ù…Ø© Ø¨ÙŠØ¶Ø§Ø¡ ({len(settings['whitelist_words']['words'])} ÙƒÙ„Ù…Ø§Øª)")

        if is_premium and settings['blacklist_words']['enabled']:
            active_filters.append(f"ğŸš« Ù‚Ø§Ø¦Ù…Ø© Ø³ÙˆØ¯Ø§Ø¡ ({len(settings['blacklist_words']['words'])} ÙƒÙ„Ù…Ø§Øª)")

        if is_premium and settings['replacements']['enabled']:
            active_filters.append(f"ğŸ”„ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ø§Øª ({len(settings['replacements']['pairs'])} Ø§Ø³ØªØ¨Ø¯Ø§Ù„)")

        if is_premium and settings['link_management']['enabled']:
            active_filters.append(f"ğŸ”— Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ({settings['link_management']['mode']})")

        if is_premium and settings['button_filter']['enabled']:
            active_filters.append(f"ğŸš« ÙÙ„ØªØ± Ø§Ù„Ø£Ø²Ø±Ø§Ø± ({settings['button_filter']['mode']})")

        if is_premium and settings['forwarded_filter']['enabled']:
            active_filters.append(f"â†ªï¸ ÙÙ„ØªØ± Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù…ÙˆØ¬Ù‡Ø© ({settings['forwarded_filter']['mode']})")

        if is_premium and settings['language_filter']['enabled']:
            active_filters.append(f"ğŸŒ ÙÙ„ØªØ± Ø§Ù„Ù„ØºØ© ({settings['language_filter']['mode']})")

        if is_premium and settings.get('day_filter', {}).get('enabled', False):
            active_filters.append(f"ğŸ“… ÙÙ„ØªØ± Ø§Ù„Ø£ÙŠØ§Ù… ({settings['day_filter']['mode']})")

        if is_premium and settings.get('hour_filter', {}).get('enabled', False):
            active_filters.append(f"ğŸ•’ ÙÙ„ØªØ± Ø§Ù„Ø³Ø§Ø¹Ø§Øª ({settings['hour_filter']['mode']})")

        if is_premium and settings.get('character_limit', {}).get('enabled', False):
            active_filters.append(f"ğŸ“ Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø£Ø­Ø±Ù ({settings['character_limit']['mode']})")

        if is_premium and settings.get('translation', {}).get('enabled', False):
            active_filters.append(f"ğŸŒ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ")

        if is_premium and settings.get('auto_pin', {}).get('enabled', False):
            active_filters.append(f"ğŸ“Œ ØªØ«Ø¨ÙŠØª ØªÙ„Ù‚Ø§Ø¦ÙŠ")

        if is_premium and settings.get('auto_delete', {}).get('enabled', False):
            active_filters.append(f"ğŸ—‘ï¸ Ø­Ø°Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ")

        if is_premium and settings.get('reply_preservation', {}).get('enabled', False):
            active_filters.append(f"ğŸ’¬ Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ÙˆØ¯")

        if is_premium and settings.get('link_preview', {}).get('enabled', False):
            active_filters.append(f"ğŸ”— Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ({settings['link_preview']['mode']})")

        if active_filters:
            summary += "\n".join([f"  â€¢ {f}" for f in active_filters])
        else:
            summary += "Ù„Ø§ ØªÙˆØ¬Ø¯ ÙÙ„Ø§ØªØ± Ù†Ø´Ø·Ø©"

        return summary

    def add_emoji_prefix(self, text: str, entities: List[Dict]) -> Tuple[str, List[Dict]]:
        """Ø¥Ø¶Ø§ÙØ© emoji ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© ÙƒÙ„ Ø³Ø·Ø± Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø­Ø³Ø§Ø¨ Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ù€ entities"""
        if not text:
            return text, entities

        emoji = "ğŸ”´"
        emoji_len = len(emoji)  # Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù (1 Ø­Ø±Ù emoji)

        lines = text.split('\n')
        new_text = ""
        offset_map = {}  # Ø®Ø±ÙŠØ·Ø© Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù‚Ø¯ÙŠÙ… -> Ø§Ù„Ø¬Ø¯ÙŠØ¯

        current_old_pos = 0
        current_new_pos = 0

        for i, line in enumerate(lines):
            # Ø­ÙØ¸ Ù…ÙˆÙ‚Ø¹ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ø·Ø±
            offset_map[current_old_pos] = current_new_pos

            if line.strip():  # Ø³Ø·Ø± ØºÙŠØ± ÙØ§Ø±Øº
                new_text += emoji + line

                # ØªØªØ¨Ø¹ ÙƒÙ„ Ù…ÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø³Ø·Ø±
                for j in range(len(line)):
                    old_pos = current_old_pos + j
                    new_pos = current_new_pos + emoji_len + j
                    offset_map[old_pos] = new_pos

                current_old_pos += len(line)
                current_new_pos += emoji_len + len(line)
            else:  # Ø³Ø·Ø± ÙØ§Ø±Øº
                new_text += line
                current_old_pos += len(line)
                current_new_pos += len(line)

            # Ø¥Ø¶Ø§ÙØ© newline Ø¥Ø°Ø§ Ù„Ù… Ù†ÙƒÙ† ÙÙŠ Ø¢Ø®Ø± Ø³Ø·Ø±
            if i < len(lines) - 1:
                new_text += '\n'
                offset_map[current_old_pos] = current_new_pos
                current_old_pos += 1
                current_new_pos += 1

        # ØªØ¹Ø¯ÙŠÙ„ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù€ entities
        if entities:
            adjusted_entities = []

            for entity in entities:
                old_offset = entity['offset']

                # Ø¥ÙŠØ¬Ø§Ø¯ Ø£Ù‚Ø±Ø¨ Ù…ÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø®Ø±ÙŠØ·Ø©
                if old_offset in offset_map:
                    new_offset = offset_map[old_offset]
                else:
                    # Ø¥ÙŠØ¬Ø§Ø¯ Ø£Ù‚Ø±Ø¨ Ù…ÙˆÙ‚Ø¹ Ø£ØµØºØ±
                    closest_offset = max([k for k in offset_map.keys() if k <= old_offset], default=0)
                    diff = old_offset - closest_offset
                    new_offset = offset_map[closest_offset] + diff

                new_entity = entity.copy()
                new_entity['offset'] = new_offset
                adjusted_entities.append(new_entity)

            return new_text, adjusted_entities

        return new_text, entities